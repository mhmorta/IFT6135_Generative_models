# -*- coding: utf-8 -*-
"""models.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qKN2R0aZhH-Uio10GfKnho5ZrTE1Bib9
"""

import torchvision.datasets
import torchvision.transforms as transforms
import torch
from torch.utils.data import dataset
import os
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.autograd import Variable
from torch.autograd import grad as torch_grad
from torchvision.utils import save_image
import torch.utils.data
import matplotlib.pyplot as plt

# !mkdir Q3_2
# !mkdir results
# !mkdir models
# !rm -r results

def get_data_loader(dataset_location, batch_size):
    transform = transforms.Compose([
                transforms.ToTensor(),
                transforms.Normalize((.5, .5, .5), (.5, .5, .5))])

    trainvalid = torchvision.datasets.SVHN(
        dataset_location, split='train',
        download=True,
        transform=transform
    )

    trainset_size = int(len(trainvalid) * 0.9)
    trainset, validset = dataset.random_split(
        trainvalid,
        [trainset_size, len(trainvalid) - trainset_size]
    )

    trainloader = torch.utils.data.DataLoader(
        trainset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=2
    )

    validloader = torch.utils.data.DataLoader(
        validset,
        batch_size=batch_size,
    )

    testloader = torch.utils.data.DataLoader(
        torchvision.datasets.SVHN(
            dataset_location, split='test',
            download=True,
            transform=transform
        ),
        batch_size=batch_size,
    )

    return trainloader, validloader, testloader

# trainloader, validloader, testloader = get_data_loader('./Q3_2/', 512)

class Flatten(nn.Module):
    def forward(self, input):
        return input.view(input.size(0), -1)


class UnFlatten(nn.Module):
    def forward(self, input, size=512):
        return input.view(input.size(0), size, 1, 1)


class Interpolate(nn.Module):
    def __init__(self, scale_factor):
        super(Interpolate, self).__init__()
        self.interp = nn.functional.interpolate
        self.scale_factor = scale_factor

    def forward(self, x):
        x = self.interp(x, scale_factor=self.scale_factor, mode='bilinear', align_corners=False)
        return x

class Generator(nn.Module):
    def __init__(self, channels, latent_dim, cuda):
        super(Generator, self).__init__()
        self.cuda = cuda

        self.mlp = nn.Sequential(
            nn.Linear(latent_dim, 128 *4* 4 * 4),
#             nn.ReLU()
            )

        self.convTranspose = nn.Sequential(
            nn.ConvTranspose2d(128*4, 64*4, 2, stride=2),
            nn.BatchNorm2d(64*4),
#             nn.Dropout2d(0.25),
            nn.ELU(),

            nn.ConvTranspose2d(64*4, 32*4, 2, stride=2),
            nn.BatchNorm2d(32*4),
#             nn.Dropout2d(0.25),
            nn.ELU(),

            nn.ConvTranspose2d(32*4, 16*4, 2, stride=2),
            nn.BatchNorm2d(16*4),
#             nn.Dropout2d(0.25),
            nn.ELU(),

#             nn.ConvTranspose2d(16*4, 16*2, 3, 1, 1),
#             nn.BatchNorm2d(16*2),
#             # nn.Dropout2d(0.25),
#             nn.ReLU(),

#             nn.ConvTranspose2d(16*2, 8*2, 4, 2, 1),
#             nn.BatchNorm2d(8*2),
# #             nn.Dropout2d(0.5),
#             nn.ELU(),

            nn.Conv2d(16*4, channels, 3, 1, 1),
            nn.Tanh()
            )
#         self.init_weights()

    def init_weights(self):
        for m in self.convTranspose:
            if isinstance(m,nn.ConvTranspose2d):
                nn.init.xavier_uniform_(m.weight)
                m.bias.data.fill_(0.01)

        if type(self.mlp) == nn.Linear:
            nn.init.xavier_uniform_(self.mlp.weight)
            self.mlp.bias.data.fill_(0.01)

    def forward(self, input):
        x = self.mlp(input)
        x = x.view(-1, 128*4, 4, 4)
        return self.convTranspose(x)

class Discriminator(nn.Module):
    def __init__(self, channels, latent_dim, cuda):
        super(Discriminator, self).__init__()
        self.cuda = cuda

        self.conv = nn.Sequential( 
            nn.Conv2d(channels, 32, 3, 2, 1),
            nn.BatchNorm2d(32),
#             nn.Dropout2d(0.25),
            nn.ReLU(),

            nn.Conv2d(32, 64, 3, 2, 1),
            nn.BatchNorm2d(64),
#             nn.Dropout2d(0.25),
            nn.ReLU(),

            nn.Conv2d(64, 128, 3, 1, 1),
            nn.BatchNorm2d(128),
#             nn.Dropout2d(0.5),
            nn.ReLU(),

            nn.Conv2d(128,256 , 3, 2, 1),
            nn.BatchNorm2d(256),
#             nn.Dropout2d(0.25),
            nn.ReLU(),

            )
        self.mlp = nn.Sequential(
            nn.Linear(256 * 4 * 4, 1000),
            nn.ReLU(),
            nn.Linear(1000, 500),
            nn.ReLU(),
            nn.Linear(500,1)
#             nn.Sigmoid()
            )

#        self.init_weights()
    def init_weights(self):
        for m in self.conv:
            if isinstance(m,nn.Conv2d):
                nn.init.xavier_uniform_(m.weight)
                m.bias.data.fill_(0.01)

        if type(self.mlp) == nn.Linear:
            nn.init.xavier_uniform_(self.mlp.weight)
            self.mlp.bias.data.fill_(0.01)

    def forward(self, input):
        x = self.conv(input)
        x = x.view(-1, 256 * 4 * 4)
        return self.mlp(x)

def sample_generator(Generator, num_samples, latent_dim, count, device):
    noise = Variable(torch.randn(num_samples, latent_dim), requires_grad=False).to(device)
    noise.require_grad = False

    gen_samples = Generator(noise)
    gen_samples = gen_samples.view(-1, 3, 32, 32)
    save_image(gen_samples.data.view(num_samples, 3, 32, 32).cpu(), 'results/gen_img_' + str(count) + '.png', nrow = 10, normalize=True)

def loss_WD(D_x, D_y, regularizer):
    lam = 25
    D_loss = (D_x.mean() - D_y.mean()) - (lam * regularizer)
    return -D_loss 


def gradient_penalty(C,x,y, batch_size, device):
     a=torch.FloatTensor(np.random.uniform(0, 1, (x.size(0), 1))).to(device).expand((x.view(-1,3*32*32)).size())
    #   print(x.view(-1,3*3*32).size())
     z=(a*x.view(-1,3*32*32)+(1-a)*y.view(-1,3*32*32)).view(-1,3,32,32)
     z= torch.autograd.Variable(z, requires_grad=True)
     Tz=C(z)
     gradients = torch.autograd.grad(Tz,z,grad_outputs= torch.ones(Tz.size()).to(device),create_graph=True, retain_graph=True, only_inputs=True)
    #   print(gradients[0].view(-1,3*32*32).size())
    #   print(((gradients[0].view(-1,3*32*32).norm(2, dim=1)-1)**2).mean())
     return ((gradients[0].view(-1,3*32*32).norm(2, dim=1)-1)**2).mean()

def train(Discriminator, Generator, trainloader, latent_dim, batch_size, epochs, device,test):
    Discriminator.train()
    Generator.train()


    optimizer_G = torch.optim.Adam(Generator.parameters(), lr=0.0002)
    optimizer_D = torch.optim.Adam(Discriminator.parameters(), lr=0.0002)

    count = 0
    for e in range(epochs):
        for i, (img, _) in enumerate(trainloader):
            batch_size = img.shape[0]
            D_x = Variable(img.to(device))

            noise = torch.randn(batch_size, latent_dim).to(device)
            D_y = Generator(noise).to(device)
            GP=gradient_penalty(Discriminator,D_x,D_y, batch_size, device)
            optimizer_D.zero_grad()
            T_x=Discriminator(D_x)
            T_y=Discriminator(D_y)
            loss_d = loss_WD(T_x,T_y,GP)
            loss_d.backward()
            optimizer_D.step()

            count=count+1
            if count % 2 == 0:
                optimizer_G.zero_grad()
                optimizer_D.zero_grad()
                noise = torch.randn(batch_size, latent_dim).to(device)
                D_y = Generator(noise).to(device)
                D_loss_fake = Discriminator(D_y)
                loss_g = -(D_loss_fake.mean())
                loss_g.backward()
                optimizer_G.step()

        print ('Epoch: ', e, 'step: ', i, 'Discriminator loss: ', loss_d.mean().cpu().data.numpy(),
            'Generator loss: ', loss_g.mean().cpu().data.numpy())
        
        results=Generator(test)
        for i in results:
          showImg(i.cpu())

        sample_generator(Generator, 100, latent_dim, e, device)

def showImg(img):
  image = np.squeeze(img.data.numpy())
#   image = (image - np.min(image)) / (np.max(image) - np.min(image))
  image=image*0.5+0.5
  image = image.transpose((1, 2, 0))
  plt.imshow(image)
  plt.show()

if __name__ == "__main__":
    # os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID" 
    # os.environ["CUDA_VISIBLE_DEVICES"] = "0"
    cuda = torch.cuda.is_available()
    # print (torch.cuda.current_device())

#     parser = argparse.ArgumentParser()
#     parser.add_argument("--epochs", type=int, default=100, help="number of epochs of training")
#     parser.add_argument("--batch_size", type=int, default=32, help="size of the batches")
#     parser.add_argument("--optimizer", type=str, default='Adam', help="type of the optimizer")
#     parser.add_argument("--lr", type=float, default=0.0002, help="adam: learning rate")
#     parser.add_argument("--latent_dim", type=int, default=100, help="dimensionality of the latent space")
#     parser.add_argument("--img_size", type=int, default=32, help="size of each image dimension")
#     parser.add_argument("--channels", type=int, default=3, help="number of image channels")
#     parser.add_argument("--sample_interval", type=int, default=400, help="interval betwen image samples")
#     parser.add_argument("--lamda", type=int, default=10, help='the lambda value for gradient penalty')
#     opt = parser.parse_args()

    device = torch.device("cuda" if cuda else "cpu")
    
  
    latent_dim = 100
    batch_size =32
    epochs = 100
    channels = 3
    
    test = torch.randn(channels, latent_dim).to(device)

    D = Discriminator(channels, latent_dim, device)
    G = Generator(channels, latent_dim, device)

    
    D.to(device)
    G.to(device)
    
    

    trainloader, validloader, testloader = get_data_loader('./Q3_2/', 512)
    train(D, G, trainloader, latent_dim, batch_size, epochs, device,test)

    name = 'svhn_model'
    torch.save(G.state_dict(), './models/gan_' + name + '.pt')
    torch.save(D.state_dict(), './models/dis_' + name + '.pt')

# from google.colab import drive
# drive.mount('/content/gdrive')

# !cp -r ./results/ ./gdrive/My\ Drive/exp1/

